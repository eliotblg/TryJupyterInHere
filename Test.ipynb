{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import gzip\n",
    "f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "training, validation, test = pickle.load(f, encoding='latin1')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = training[0][:]\n",
    "labels = training[1][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "def dsigmoid(x):\n",
    "    return x * (1.0 - x)\n",
    "def softplus(x):\n",
    "    return np.log(1.0 + np.exp(x))\n",
    "def dsoftplus(x):\n",
    "    return 1.0 - np.exp(-x)\n",
    "def softmax(x):\n",
    "    ex = np.exp(x)\n",
    "    return ex / np.sum(ex)\n",
    "def dsoftmax(x):\n",
    "    return x*(1.0-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nneurons = 500\n",
    "noutput  = 10\n",
    "nintlayers = 3\n",
    "nlayers      = nintlayers + 2\n",
    "initialscale = 0.01\n",
    "learningrate = 0.01\n",
    "dropout      = 0.5\n",
    "momentum     = 0.75\n",
    "nbatch       = 100\n",
    "nimages      = len(images)\n",
    "nupdates     = round(nimages / nbatch) * 100\n",
    "\n",
    "class Layer():\n",
    "    def __init__(self, nneurons, afunc, pn = -1):\n",
    "        self.nneurons=nneurons\n",
    "        self.afunc = afunc\n",
    "        if afunc == sigmoid:\n",
    "            self.dfunc = dsigmoid\n",
    "        if afunc == softplus:\n",
    "            self.dfunc = dsoftplus\n",
    "        if afunc == softmax:\n",
    "            self.dfunc = dsoftmax\n",
    "        self.b  = np.random.normal(size=nneurons) * initialscale\n",
    "        self.db = np.zeros(nneurons)\n",
    "        if pn > 0:\n",
    "            self.w  = np.random.normal(size=[pn, nneurons]) * initialscale\n",
    "            self.dw = np.zeros([pn, nneurons])\n",
    "        else:\n",
    "            self.w  = None\n",
    "            self.dw = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove(n):\n",
    "    return np.where(np.random.random(n) > dropout, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 784\n",
      "500 500\n",
      "500 500\n"
     ]
    }
   ],
   "source": [
    "nn= [Layer(len(images[1]), sigmoid)]\n",
    "for i in range(1, nintlayers+1):\n",
    "    nn.append(Layer(nneurons, softplus, pn = nn[i-1].nneurons))\n",
    "    print(nneurons, nn[i-1].nneurons)\n",
    "nn.append(Layer(noutput, softmax, pn = nn[nlayers-2].nneurons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[573 439 497 408 240 626 263 458 439 261 406 408 573 573 406 292 263 517\n",
      " 439 517 547 688 437 439 440 263 573 517 573 573 573 517 263 573 406 263\n",
      " 573 517 565 573 573 573 240 265 408 293 497 458 517 263 263 573 458 573\n",
      " 536 632 517 497 437 497 497 439 292 439 573 263 573 573 540 573 573 573\n",
      " 573 573 654 122 497 239  93 688 263 292 263 292 517 458 159 688 497 573\n",
      " 292 632 540 573 497 431 240 159 497 242]\n",
      "[321 321 321 321 321 321 321 321 321 321 321 321 321 321 321 321 321 321\n",
      " 321 188 321 321 321 321 321 321 321 321 321 321 321 321 321 321 321 321\n",
      " 321 321 321 321 321 321 321 321 321 321 321 321 321 321 188 321 321 321\n",
      " 321 321 321 321 321 321 321 321 321 321 321 321 321 321 321 321 321 321\n",
      " 321 321 321 321 321 321 321 321 321 321 321 321 321 321 321 321 321 321\n",
      " 321 321 321 321 321 321 321 321 321 321]\n",
      "[241 241 241 241 241 241 241 241 241 241 241 241 241 241 241 241 241 241\n",
      " 241 241 241 241 241 241 241 241 241 241 241 241 241 241 241 241 241 241\n",
      " 241 241 241 241 241 241 241 241 241 241 241 241 241 241 241 241 241 241\n",
      " 241 241 241 241 241 241 241 241 241 241 241 241 241 241 241 241 241 241\n",
      " 241 241 241 241 241 241 241 241 241 241 241 241 241 241 241 241 241 241\n",
      " 241 241 241 241 241 241 241 241 241 241]\n",
      "[301 301 301 301 301 301 301 301 301 301 301 301 301 301 301 301 301 301\n",
      " 301 301 301 301 301 301 301 301 301 301 301 301 301 301 301 301 301 301\n",
      " 301 301 301 301 301 301 301 301 301 301 301 301 301 301 301 301 301 301\n",
      " 301 301 301 301 301 301 301 301 301 301 301 301 301 301 301 301 301 301\n",
      " 301 301 301 301 301 301 301 301 301 301 301 301 301 301 301 301 301 301\n",
      " 301 301 301 301 301 301 301 301 301 301]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "nupdates = 1\n",
    "for k in range(nupdates):\n",
    "    \n",
    "    r = [1.0] + [ remove(nneurons) for l in nn[1:-1] ] + [1.0]\n",
    "\n",
    "    batchindexes = np.random.randint(nimages, size=nbatch)\n",
    "    x = images[batchindexes]     # 6.0 and 3.0 are empirical and could be added to w and b\n",
    "    expected = np.zeros([nbatch, noutput])\n",
    "    for i, j in enumerate(batchindexes):\n",
    "        expected[i, labels[j]] = 1.0\n",
    "        \n",
    "    \n",
    "    # \"propagate\" y = f(w*x + b)\n",
    "    #\n",
    "    y = [nn[0].afunc(x + nn[0].b)]\n",
    "    print(np.argmax(y[0],axis=1))\n",
    "    #print(y[0])\n",
    "    #print(x + nn[0].b)\n",
    "    for i in range(1, nlayers):\n",
    "        #y.append(  (np.matmul(y[i-1],nn[i].w) + nn[i].b ) * r[i] )\n",
    "        #y.append( nn[i].afunc( np.matmul(y[i-1],nn[i].w) + nn[i].b ) * r[i] )\n",
    "        y.append( nn[i].afunc( np.matmul(y[i-1],nn[i].w) + nn[i].b ) * r[i] ) \n",
    "        #print(np.argmax(y[i],axis=1))\n",
    "        #print(nn[i].w)\n",
    "        #print(y[i-1])\n",
    "        print(np.argmax(y[i],axis = 1))\n",
    "    # estimate errors (e) backprogapagation to evaluate derivatives with respect to results\n",
    "    #\n",
    "    e = [expected - y[nintlayers +1]]\n",
    "    for i in range(nintlayers, -1, -1):\n",
    "        e = [np.matmul(e[0], nn[i+1].w.transpose()) * nn[i].dfunc(y[i]) * r[i]] + e\n",
    "    for i in range(nlayers):\n",
    "            nn[i].db += np.sum(e[i])\n",
    "            nn[i].b  += learningrate * nn[i].db\n",
    "            nn[i].db *= momentum\n",
    "            if type(nn[i].w) is np.ndarray:\n",
    "                nn[i].dw += np.sum(np.matmul(y[i-1].transpose(), e[i]))\n",
    "                nn[i].w  += nn[i].dw * learningrate\n",
    "                nn[i].dw *= momentum\n",
    "\n",
    "    ncorrect = np.sum(np.argmax(y[4],axis=1) == labels[batchindexes]) \n",
    "    learningrate *= (nupdates - k) / (nupdates - k + 1)   \n",
    "\n",
    "    if k != 0 and k%100 == 0:\n",
    "        print('-------------')\n",
    "        print('Itereation ' + str(k))\n",
    "        print(str(100*ncorrect/nbatch)+ '% correct')\n",
    "        print(np.argmax(y[4],axis=1))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningrate = 0.001\n",
    "dropout      = 0.5\n",
    "momentum     = 0.75\n",
    "nbatch       = 100\n",
    "nimages      = len(images)\n",
    "nupdates     = round(nimages / nbatch) * 100\n",
    "\n",
    "def remove(n):\n",
    "    return np.where(np.random.random(n) > dropout, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78400, 50000, 50000, 50000, 1000]\n",
      "3\n",
      "2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (500,100) and (500,500) not aligned: 100 (dim 1) != 500 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-7a42d7fd33f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         e[i] = np.dot( nnetwork[i].dfunc(y[i]).transpose(),\n\u001b[0;32m---> 24\u001b[0;31m             np.matmul(e[i+1], weigth[i].transpose()) )     \n\u001b[0m\u001b[1;32m     25\u001b[0m        \u001b[0;31m# e[i] = e[i].transpose()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (500,100) and (500,500) not aligned: 100 (dim 1) != 500 (dim 0)"
     ]
    }
   ],
   "source": [
    "nupdates = 1\n",
    "for i in range(nupdates):\n",
    "    \n",
    "    r = [ remove(l.nneurons) for l in nnetwork[1:-1] ] \n",
    "\n",
    "    batchindexes = np.random.randint(nimages, size=nbatch)\n",
    "    x = 6.0 * images[batchindexes]+ 3\n",
    "    expected = np.zeros([nbatch, noutput])\n",
    "    for i, j in enumerate(batchindexes):\n",
    "        expected[i, labels[j]] = 1\n",
    "\n",
    "        \n",
    "    y = []\n",
    "    y.append(nnetwork[0].afunc(x+ nnetwork[0].b))\n",
    "    for i in range(1, nintlayers+2):\n",
    "        y.append(nnetwork[i].afunc( np.matmul(y[i-1], weigth[i-1]) + nnetwork[i].b ) )\n",
    "\n",
    "    print([t.size for t in y])\n",
    "    e = [[] for i in range(nintlayers + 2)]\n",
    "    e[nintlayers + 1] = expected - y[nintlayers +1]\n",
    "    for i in range(nintlayers, 0, -1):\n",
    "        print(i)\n",
    "        e[i] = np.dot( nnetwork[i].dfunc(y[i]).transpose(),\n",
    "            np.matmul(e[i+1], weigth[i].transpose()) )     \n",
    "       # e[i] = e[i].transpose()\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #e = [[] for i in range(nintlayers + 2)]\n",
    "    #e[nintlayers + 1] = expected - y[nintlayers +1]\n",
    "    #for i in range(nintlayers, -1, -1):\n",
    "    #    e[i] = np.matmul(e[i+1], nn[i+1].w.transpose()) * nn[i].dfunc(y[i]) * r[i]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

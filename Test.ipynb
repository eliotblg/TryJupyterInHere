{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import gzip\n",
    "f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "training, validation, test = pickle.load(f, encoding='latin1')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "images = training[0][:] \n",
    "labels = training[1][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "def dsigmoid(x):\n",
    "    return x * (1.0 - x)\n",
    "def softplus(x):\n",
    "    return np.log(1.0 + np.exp(x))\n",
    "def dsoftplus(x):\n",
    "    return 1.0 - np.exp(-x)\n",
    "def softmax(x):\n",
    "    ex = np.exp(x)\n",
    "    return ex / np.sum(ex)\n",
    "def dsoftmax(x):\n",
    "    return x*(1.0-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "nneurons = 500\n",
    "noutput  = 10\n",
    "nintlayers = 3\n",
    "initialscale = 0.1\n",
    "class Layer():\n",
    "    def __init__(self, nneurons, afunc):\n",
    "        self.nneurons=nneurons\n",
    "        self.afunc = afunc\n",
    "        if afunc == sigmoid:\n",
    "            self.dfunc = dsigmoid\n",
    "        if afunc == softplus:\n",
    "            self.dfunc = dsoftplus\n",
    "        if afunc == softmax:\n",
    "            self.dfunc = dsoftmax\n",
    "        self.b = np.random.normal(size=nneurons) * initialscale\n",
    "        self.db = np.zeros(nneurons)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnetwork = [Layer(len(images[1]), sigmoid)]\n",
    "weigth = []\n",
    "dw = []\n",
    "for i in range(nintlayers):\n",
    "    nnetwork.append(Layer(nneurons, softplus))\n",
    "    weigth.append(np.random.normal( \\\n",
    "        size=[nnetwork[i].nneurons, nneurons]) * initialscale)\n",
    "    dw.append(np.zeros([nnetwork[i].nneurons, nneurons]))\n",
    "nnetwork.append(Layer(noutput, softmax))\n",
    "weigth.append(np.random.normal(     \\\n",
    "        size=[nnetwork[nintlayers].nneurons, noutput]) * initialscale)\n",
    "dw.append(np.zeros([nnetwork[nintlayers].nneurons, noutput]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningrate = 0.001\n",
    "dropout      = 0.5\n",
    "momentum     = 0.75\n",
    "nbatch       = 100\n",
    "nimages      = len(images)\n",
    "nupdates     = round(nimages / nbatch) * 100\n",
    "\n",
    "def remove(n):\n",
    "    return np.where(np.random.random(n) > dropout, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (500,500) and (100,500) not aligned: 500 (dim 1) != 100 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-357-84641dccf74f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         e[i] = np.dot( \n\u001b[1;32m     26\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweigth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mnnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m               )\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (500,500) and (100,500) not aligned: 500 (dim 1) != 100 (dim 0)"
     ]
    }
   ],
   "source": [
    "nupdates = 1\n",
    "for i in range(nupdates):\n",
    "    \n",
    "    r = [ remove(l.nneurons) for l in nnetwork[1:-1] ] \n",
    "\n",
    "    batchindexes = np.random.randint(nimages, size=nbatch)\n",
    "    x = 6.0 * images[batchindexes] + 3\n",
    "    expected = np.zeros([nbatch, noutput])\n",
    "    for i, j in enumerate(batchindexes):\n",
    "        expected[i, labels[j]] = 1\n",
    "\n",
    "        \n",
    "    y = []\n",
    "    y.append(nnetwork[0].afunc(x + nnetwork[0].b))\n",
    "    for i in range(1, nintlayers+2):\n",
    "        # transpose of product is product of transposes in reverse order\n",
    "        y.append(nnetwork[i].afunc( \n",
    "            np.matmul(y[i-1], weigth[i-1]) + nnetwork[i].b ))\n",
    "\n",
    "        \n",
    "    e = [[] for i in range(nintlayers + 2)]\n",
    "    e[nintlayers + 1] = expected - y[nintlayers +1]\n",
    "    for i in range(nintlayers, 0, -1):\n",
    "        print(i)\n",
    "        e[i] = np.dot( \n",
    "            np.matmul(e[i+1], weigth[i].transpose()).transpose(),\n",
    "            nnetwork[i].dfunc(y[i])\n",
    "              )\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
